{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRFQ7POhYRp7",
        "outputId": "8429bafa-a762-4a73-af34-7f9376c13c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Interlub/orders_preprocessed.csv')\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "# Agrupar por semana y por 'product_id', sumando solo 'quantity'\n",
        "df_weekly = df.groupby([pd.Grouper(key='date', freq='W'), 'product_id'])['quantity'].sum().reset_index()\n",
        "df_weekly.head()"
      ],
      "metadata": {
        "id": "AkOuoWTZdovp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "1v8LhPzTqwaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import root_mean_squared_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "from prophet import Prophet\n",
        "from prophet.diagnostics import cross_validation\n",
        "from prophet.diagnostics import performance_metrics\n",
        "\n",
        "from statsforecast.models import AutoETS\n",
        "from statsforecast import StatsForecast\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "import logging\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n",
        "logging.getLogger('prophet').setLevel(logging.WARNING)\n",
        "logging.getLogger('fbprophet').setLevel(logging.WARNING)\n",
        "\n",
        "\n",
        "def fitLinearRegression(product_id, product_series):\n",
        "    product_series = product_series.copy()\n",
        "    product_series['time_numeric'] = (product_series['ds'] - product_series['ds'].min()).dt.days\n",
        "    X = product_series.index.values.reshape(-1, 1)\n",
        "    y = product_series['y'].values  # Target variable\n",
        "    model = LinearRegression()\n",
        "\n",
        "    # Define Time Series Split\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    rmse_scores = []\n",
        "\n",
        "    for train_index, test_index in tscv.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        rmse = root_mean_squared_error(y_test, y_pred)\n",
        "        rmse_scores.append(rmse)\n",
        "\n",
        "    # Store results\n",
        "    lr_results = [{\n",
        "        'product_id': product_id,\n",
        "        'LR_rmse': np.mean(rmse_scores),\n",
        "    }]\n",
        "    return pd.DataFrame(lr_results)\n",
        "\n",
        "\n",
        "def fitArima(product_id, product_series, p,d,q):\n",
        "    product_series = product_series.copy()\n",
        "    product_series = product_series.drop(columns=['ds'])\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    rmse_scores = []\n",
        "\n",
        "    for train_index, test_index in tscv.split(product_series):\n",
        "        train, test = product_series.iloc[train_index], product_series.iloc[test_index]\n",
        "\n",
        "        # Fit ARIMA model\n",
        "        model = ARIMA(train, order=(p, d, q))  # Adjust (p, d, q) as needed\n",
        "        model_fit = model.fit()\n",
        "\n",
        "        # Predict and evaluate\n",
        "        predictions = model_fit.forecast(steps=len(test))\n",
        "        rmse = root_mean_squared_error(test, predictions)\n",
        "        rmse_scores.append(rmse)\n",
        "\n",
        "    arima_results = [{\n",
        "        'product_id': product_id,\n",
        "        'ARIMA_rmse': np.mean(rmse_scores),\n",
        "    }]\n",
        "    return pd.DataFrame(arima_results)\n",
        "\n",
        "\n",
        "def fitProphet(product_id, product_series):\n",
        "    product_series = product_series.copy()\n",
        "    modelo = Prophet()\n",
        "    modelo.fit(product_series)\n",
        "    futuro = modelo.make_future_dataframe(periods=5)\n",
        "    prediccion = modelo.predict(futuro)\n",
        "\n",
        "    #Cross-validation\n",
        "    df_cv = cross_validation(modelo, initial='540 days', period='90 days', horizon='180 days')\n",
        "    rmse_scores = performance_metrics(df_cv)['rmse']\n",
        "\n",
        "    prophet_results = [{\n",
        "        'product_id': product_id,\n",
        "        'PROPHET_rmse': np.mean(rmse_scores),\n",
        "    }]\n",
        "    return pd.DataFrame(prophet_results)\n",
        "\n",
        "def fitProphetLog(product_id, product_series):\n",
        "    product_series = product_series.copy()\n",
        "\n",
        "    product_series['cap'] = product_series['y'].max()\n",
        "    product_series['floor'] = 0\n",
        "\n",
        "    modelo = Prophet(growth='logistic')\n",
        "    modelo.fit(product_series)\n",
        "    futuro = modelo.make_future_dataframe(periods=5)\n",
        "    futuro['cap'] = product_series['y'].max()\n",
        "    futuro['floor'] = 0\n",
        "\n",
        "    prediccion = modelo.predict(futuro)\n",
        "\n",
        "    #Cross-validation\n",
        "    df_cv = cross_validation(modelo, initial='540 days', period='90 days', horizon='180 days')\n",
        "    rmse_scores = performance_metrics(df_cv)['rmse']\n",
        "\n",
        "    prophetlog_results = [{\n",
        "        'product_id': product_id,\n",
        "        'PROPHETLOG_rmse': np.mean(rmse_scores),\n",
        "    }]\n",
        "\n",
        "    return pd.DataFrame(prophetlog_results)\n",
        "\n",
        "def fitAutoEts(product_id, product_series):\n",
        "    sf_df = product_series.copy()\n",
        "    sf_df['unique_id'] = product_id  # StatsForecast requires this column\n",
        "    models = [AutoETS(season_length=52, model='ZZZ', alias='AutoETS')]\n",
        "    sf = StatsForecast(models=models, freq='W', n_jobs=-1)\n",
        "\n",
        "    cv_df = sf.cross_validation(\n",
        "        df=sf_df,\n",
        "        h=12,           # Forecast horizon (12 weeks ~ 3 months)\n",
        "        n_windows=5,     # 5 folds of cross-validation\n",
        "        step_size=24,    # Move 24 weeks (~6 months) between windows\n",
        "        test_size=156-24 # Ensure we have enough training data (132 weeks for first fold)\n",
        "    )\n",
        "\n",
        "    # Calculate RMSE for our specific model\n",
        "    mean_fold_rmse = cv_df.groupby('cutoff').apply(\n",
        "        lambda x: np.sqrt(mean_squared_error(x['y'], x['AutoETS']))).mean()\n",
        "\n",
        "    return pd.DataFrame([{\n",
        "        'product_id': product_id,\n",
        "        'AUTOETS_rmse': mean_fold_rmse,\n",
        "    }])\n",
        "\n",
        "\n",
        "\n",
        "def fitLSTM(product_id, product_series, look_back=10, epochs=20, batch_size=32):\n",
        "    # Prepare data\n",
        "    data = product_series[['y']].values\n",
        "    dates = product_series['ds'].values\n",
        "\n",
        "    if len(data) <= look_back * 2:  # Need enough data for sequences\n",
        "        return pd.DataFrame([{\n",
        "            'product_id': product_id,\n",
        "            'LSTM_rmse': np.nan,\n",
        "        }])\n",
        "\n",
        "    # Normalize data\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "    # Create sequences\n",
        "    def create_sequences(dataset, look_back):\n",
        "        X, y = [], []\n",
        "        for i in range(len(dataset) - look_back):\n",
        "            X.append(dataset[i:i+look_back, 0])\n",
        "            y.append(dataset[i+look_back, 0])\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    X, y = create_sequences(scaled_data, look_back)\n",
        "    X = X.reshape((X.shape[0], X.shape[1], 1))  # Reshape for LSTM\n",
        "\n",
        "    # Time Series Cross-Validation\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    rmse_scores = []\n",
        "\n",
        "    for train_index, test_index in tscv.split(X):\n",
        "        try:\n",
        "            # Split data\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "            # Build LSTM model\n",
        "            model = Sequential()\n",
        "            model.add(LSTM(50, input_shape=(look_back, 1)))\n",
        "            model.add(Dense(1))\n",
        "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "            # Train\n",
        "            model.fit(X_train, y_train,\n",
        "                     epochs=epochs,\n",
        "                     batch_size=batch_size,\n",
        "                     verbose=0)\n",
        "\n",
        "            # Predict and inverse transform\n",
        "            predictions = model.predict(X_test, verbose=0)\n",
        "            predictions = scaler.inverse_transform(predictions)\n",
        "            y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "            # Calculate RMSE\n",
        "            rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
        "            rmse_scores.append(rmse)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in fold for product {product_id}: {str(e)}\")\n",
        "            rmse_scores.append(np.nan)\n",
        "            continue\n",
        "\n",
        "    # Return results in same format as other models\n",
        "    return pd.DataFrame([{\n",
        "        'product_id': product_id,\n",
        "        'LSTM_rmse': np.nanmean(rmse_scores),  # Handles any NaN folds\n",
        "    }])"
      ],
      "metadata": {
        "id": "PGCt0Z5zqy8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import root_mean_squared_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "products = df_weekly['product_id'].unique()\n",
        "all_results = []\n",
        "final_metrics = pd.DataFrame()\n",
        "\n",
        "for product_id in products:\n",
        "    product_df = df_weekly[df_weekly['product_id'] == product_id].copy()\n",
        "    product_df = product_df.sort_values('date')\n",
        "    product_df = product_df.reset_index(drop=True)\n",
        "    product_df = product_df.drop(columns=['product_id'])\n",
        "    product_df = product_df.rename(columns={'date': 'ds', 'quantity': 'y'})\n",
        "\n",
        "    lr_results = fitLinearRegression(product_id, product_df)\n",
        "    arima_results = fitArima(product_id, product_df, p=1, d=0, q=1)\n",
        "    prophet_results = fitProphet(product_id, product_df)\n",
        "    prophet_log_results = fitProphetLog(product_id, product_df)\n",
        "    autoets_results = fitAutoEts(product_id, product_df)\n",
        "    lstm_results = fitLSTM(product_id, product_df)\n",
        "\n",
        "    product_results = prophet_results.merge(lr_results, on='product_id', how='outer').merge(\n",
        "                      arima_results, on='product_id', how='outer').merge(\n",
        "                      prophet_log_results, on='product_id', how='outer').merge(\n",
        "                      autoets_results, on='product_id', how='outer').merge(\n",
        "                      lstm_results, on='product_id', how='outer')\n",
        "\n",
        "    all_results.append(product_results)\n",
        "\n",
        "final_metrics = pd.concat(all_results, ignore_index=True)"
      ],
      "metadata": {
        "id": "gaiIHHsVea2w",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_rows\", None)\n",
        "final_metrics"
      ],
      "metadata": {
        "id": "NG3VMjjLyAOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_values = final_metrics.select_dtypes(include=['number']).mean()\n",
        "print(\"Mean values for each metric:\")\n",
        "print(mean_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYmH1fQU4ug_",
        "outputId": "8e1d6904-70e5-4e6c-aa27-a92da10053b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean values for each metric:\n",
            "PROPHET_rmse       268.822707\n",
            "LR_rmse            258.887531\n",
            "ARIMA_rmse         242.225624\n",
            "PROPHETLOG_rmse    305.205552\n",
            "AUTOETS_rmse       232.263085\n",
            "LSTM_rmse          241.924647\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}